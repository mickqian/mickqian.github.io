
## Consistent Hashing
ä¿è¯å½“æœºå™¨å¢åŠ æˆ–è€…å‡å°‘æ—¶ï¼ŒèŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®è¿ç§»åªé™äºä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´ï¼Œä¸ä¼šé€ æˆå…¨å±€çš„ç½‘ç»œé—®é¢˜
ç¯å½¢hash


### Consistency ä¸€è‡´æ€§

å¼ºåº¦ä»é«˜åˆ°ä½ï¼š
1. strong consistency
2. linear consistency/read-after-write    write-write consistency
3. å•è°ƒè¯»ä¸€è‡´æ€§ å‰ç¼€ä¸€è‡´æ€§ 
4. Casual consistency
5. eventual consistency

#### Linear Consistency
aka atomic consistency/strong consistency/immediate consistency/external consistency
#### Basic idea
è®©ä¸€ä¸ªç³»ç»Ÿçœ‹èµ·æ¥å¥½åƒåªæœ‰**ä¸€ä¸ª**æ•°æ®å‰¯æœ¬ï¼Œä¸”æ‰€æœ‰æ“ä½œå‡ä¸ºåŸå­æ€§


#### Eventual Consistency

å¸¸ç”¨å®ç°æ‰‹æ®µï¼š
* è¯»ä¿®å¤ï¼šä»replicasä¸­è¯»ï¼Œå°†ç¼ºå¤±å˜æ›´å‘é€ç»™ç›¸åº”replica, æ¶ˆé™¤å‰¯æœ¬æ•°æ®ä¸ä¸€è‡´é—®é¢˜
* å†™ä¿®å¤:  primary çš„å†™æ“ä½œç›´åˆ° follower çš„å†™æˆåŠŸåæ‰å®Œæˆ
* async repairï¼šrunning data consistency checks




### Leaderless æ— ä¸»
peer-to-peer
dynamo, riak, cassandra, voldemort
easy to write

#### Quorum æ³•å®šäººæ•°
w + r > nï¼Œ æ‰èƒ½ä¿è¯è‡³å°‘æœ‰ä¸€ä¸ªå‰¯æœ¬æ˜¯æœ€æ–°çš„


### Idempotency


### Sharding
#### vs replication
solve the problem of cost(CPU, network bandwidth, disk IO, etc)

#### problems
* **Rebalancing**:  if a particular data blows the storage capacity for the shard
* Reports require running same query on all shards


### Denormalize
techniques used to accelerate some specific querys/performance, including:
1. insert redundent key, according to specific query
2. insert derived key, as precalcualation or cache result
3. re-organize tables: if the result of merging two tables is required
4. split tables: Massive table or cold columns, to accelerate or decrese table size


### Not Only SQL
types:
* kv
* column
* document-based: json, Dynamo
* graph: Neo4j, complex relations

#### features
partitions based on hash

#### pros
* scale easily 
* write fast

#### cons
* query only on primary key
* consistency


* Not tabular relations
* More flexible
* Compromise consitency, in favor of availability and speed

### Graph Database
SQL Server
highly-related
pro:
1. fast relation-query operation


### Cache
#### Write/read-through
update cache & database
ç”±ç¼“å­˜ä½œä¸ºæ•°æ®åº“çš„ä»£ç†ï¼Œå’Œæ•°æ®åº“è¿›è¡Œäº¤äº’
**strong consistency**
##### Read through
check cache
* hit: return
* miss: load from database, return
##### Write through
check cache
* hit: update cached value, sync update database
* miss: update database

##### Write invalidate
update database, invalidate cache

#### Write back/Write behind
update cache only, **async** update database
used in write-heavy scenarios


### Transaction
group read/writes into a logical unit, to avoid worrying about partial failure

multi-object transactions: difficult to implement. object here means table, file, mq, etc. Put data of a transaction into a single partition to speedup.

foreign key: avoid

dirty read/write, solved by :
1. locking before read/write/commit, not work well when there's a long-running write transaction
2. or 

#### Snapshot Isolation/read skew
transactions are allowed in repeatable reads(which can be combined as a single transaction)
solution: reads from a *consistent snpashot* of the database


isolation
read-committed: 

concurrency control
isolation-level

multi-version concurrency controlï¼šæ— é”å®ç°ï¼Œæ—¶é—´æ—©çš„ä¼˜å…ˆï¼Œåªèƒ½è¯»æ¯”å½“å‰ğŸœæ—©çš„ transactionï¼Œ

visibility rule: object not visible/deleted until finally commited


#### Read modify write/Lost Update
cause: two writes depends on the same old read data, and write accordingly
Solution: 
	1. atomic writeï¼Œ `update cnt set v = v + 1`
	2. Automatically detect lost updates, abort and retry
	3. CAS: compare(old value and latest value) and swap
	4. CRDT: writes in a replicated context, especially if thery are commulative/swappable

LWW could cause lost update