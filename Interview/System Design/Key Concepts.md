
### Consistent Hashing
ä¿è¯å½“æœºå™¨å¢åŠ æˆ–è€…å‡å°‘æ—¶ï¼ŒèŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®è¿ç§»åªé™äºä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´ï¼Œä¸ä¼šé€ æˆå…¨å±€çš„ç½‘ç»œé—®é¢˜
ç¯å½¢hash

### Partition
failover:
	1. detect
	2. elect new leader:consensus algo
	3. reconfigure

*split brain*

logical log: decoupled from the storage engine internals
write-ahead log:

### Consistency ä¸€è‡´æ€§

å¼ºåº¦ä»é«˜åˆ°ä½ï¼š
1. strong consistency
2. linear consistency/read-after-write    write-write consistency
3. å•è°ƒè¯»ä¸€è‡´æ€§ å‰ç¼€ä¸€è‡´æ€§ 
4. Casual consistency
5. eventual consistency

#### Linear Consistency
aka atomic consistency/strong consistency/immediate consistency/external consistency
#### Basic idea
è®©ä¸€ä¸ªç³»ç»Ÿçœ‹èµ·æ¥å¥½åƒåªæœ‰**ä¸€ä¸ª**æ•°æ®å‰¯æœ¬ï¼Œä¸”æ‰€æœ‰æ“ä½œå‡ä¸ºåŸå­æ€§


#### Eventual Consistency

å¸¸ç”¨å®ç°æ‰‹æ®µï¼š
* è¯»ä¿®å¤ï¼šä»replicasä¸­è¯»ï¼Œå°†ç¼ºå¤±å˜æ›´å‘é€ç»™ç›¸åº”replica, æ¶ˆé™¤å‰¯æœ¬æ•°æ®ä¸ä¸€è‡´é—®é¢˜
* å†™ä¿®å¤:  primary çš„å†™æ“ä½œç›´åˆ° follower çš„å†™æˆåŠŸåæ‰å®Œæˆ
* async repairï¼šrunning data consistency checks



### Leaderless æ— ä¸»
peer-to-peer
dynamo, riak, cassandra, voldemort
easy to write

#### Quorum æ³•å®šäººæ•°
w + r > nï¼Œ æ‰èƒ½ä¿è¯è‡³å°‘æœ‰ä¸€ä¸ªå‰¯æœ¬æ˜¯æœ€æ–°çš„


### Idempotency


### Sharding
#### vs replication
solve the problem of cost(CPU, network bandwidth, disk IO, etc)

#### problems
* **Rebalancing**:  if a particular data blows the storage capacity for the shard
* Reports require running same query on all shards


### Denormalize
techniques used to accelerate some specific querys/performance, including:
1. insert redundent key, according to specific query
2. insert derived key, as precalcualation or cache result
3. re-organize tables: if the result of merging two tables is required
4. split tables: Massive table or cold columns, to accelerate or decrese table size


### Not Only SQL
types:
* kv
* column-based: column data stored in separated files, when reading few columns, reading all columns from transactional-database can be too much. Column files can be compressed as bitmap, or run-length if it's sparse
* document-based: json, Dynamo
* graph: Neo4j, complex relations

#### features
partitions based on hash

#### pros
* scale easily 
* write fast

#### cons
* query only on primary key
* consistency


* Not tabular relations
* More flexible
* Compromise consitency, in favor of availability and speed
* Eventual but not linear consistency

#### Pros
* speed, availabilities


#### Cons
* lack of consistency
* lack of ACID transactions
* lack of standard Structued Query Language interface

### Graph Database
SQL Server
highly-related
pro:
1. fast relation-query operation


### Cache
#### Write/read-through
update cache & database
ç”±ç¼“å­˜ä½œä¸ºæ•°æ®åº“çš„ä»£ç†ï¼Œå’Œæ•°æ®åº“è¿›è¡Œäº¤äº’
**strong consistency**
##### Read through
check cache
* hit: return
* miss: load from database, return
##### Write through
check cache
* hit: update cached value, sync update database
* miss: update database

##### Write invalidate
update database, invalidate cache

#### Write back/Write behind
update cache only, **async** update database
used in write-heavy scenarios


### Transaction
group read/writes into a logical unit, to avoid worrying about partial failure

Atomic is for abort

multi-object transactions: difficult to implement. object here means table, file, mq, etc. Put data of a transaction into a single partition to speedup.

foreign key: avoid

dirty read/write, solved by :
1. locking before read/write/commit, not work well when there's a long-running write transaction
2. or 

#### Snapshot Isolation/read skew
transactions are allowed in repeatable reads(which can be combined as a single transaction)
solution: reads from a *consistent snpashot* of the database


isolation-levels
* read uncommitted: 
* read committed(default): 1.  è¯»æ•°æ®åº“æ—¶ï¼Œåªä¼šè¯»åˆ°å·²æäº¤çš„æ•°æ®ã€‚(æ— è„è¯»), å†™æ•°æ®åº“æ—¶ï¼Œåªä¼šè¦†ç›–å·²ç»æäº¤çš„æ•°æ®ã€‚(æ— è„å†™)
* repeatable read: åªèƒ½è¯»åˆ°è¯¥äº‹åŠ¡å¯åŠ¨æ—¶å·²ç»æäº¤çš„å…¶ä»–äº‹åŠ¡ä¿®æ”¹çš„æ•°æ®
	* con: phantom read: ç”±äºåªé”ä½æ—§æ•°æ®ï¼ŒåŒä¸€æŸ¥è¯¢è¯­å¥å¯èƒ½è¿”å›æ–°æ•°æ®
* serializability:
* snapshot isolation: ä½¿ç”¨ mvcc çš„æ— é”ç‰¹æ€§æ¥æé«˜æ€§èƒ½ï¼Œå› ä¸ºå¯¹ä¸€ä¸ª key èƒ½å¤Ÿä¿å­˜å¤šä¸ªç‰ˆæœ¬çš„æ•°æ®ï¼ŒSI èƒ½å¤Ÿåšåˆ°è¯»ä¸é˜»å¡å†™ï¼Œç”šè‡³å†™ä¹Ÿä¸é˜»å¡å†™ã€‚
	* con: write skew

**multi-version concurrency control**ï¼šclock-based, æ— é”å®ç°ï¼Œæ—¶é—´æ—©çš„ä¼˜å…ˆï¼Œåªèƒ½è¯»æ¯”å½“å‰ğŸœæ—©çš„ transactionï¼Œ

visibility rule: object not visible/deleted until finally commited

#### Read modify write/Lost Update
cause: two writes depends on the same old read data, and write accordingly
Solution: 
	1. atomic write, `update cnt set v = v + 1`
	2. locking, starvation
	3. Automatically detect lost updates, abort and retry
	4. CAS: compare(old value and latest value) and swap
		* not working for snapshots
	5. Conflict resolving: 
		* CRDT: writes in a replicated context, especially if thery are commulative/swappable

LWW could cause lost update

#### Write skew
read-update-write 

* optimistic locking: instead of blocking, transactions continues anyway, and database check when committing
	* contention low
* pessmisitic locking: wait until the situation is safe(no race condition)
	* contention high


* 2-phase locking/read-write lock: provides serializebility
all reads - all writes
* predicate lock: not perform well
* index range lock: allows database to lock access to all rows matching some query
